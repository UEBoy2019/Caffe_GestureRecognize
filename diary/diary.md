## 原由：  
做些记录，做些改变，做些目标

## 9.30
一个开始，想要用设计模式来构造一个图像识别的框架，算法是caffe框架，图像来源可以是本地文件/本地摄像头/网络资源，功能菜单可以交互地设置一些参数，循环选择一个功能。  
没有弹性的设计已经实现了，基本是一个实现依赖于另一个实现，在功能欠缺(3个)的情况下还可以维护，但不符合封装的思想，也不符合编程规范。  
也想要开展一个项目，熟悉一下编程生活。  
当然，准确地说，有以下几个方面的渴望进步：  
1. caffe 的应用，图像识别方向。
2. 设计模式的应用，可扩展，可复用，可维护。
3. C++ 编程的规范
4. git 和 GitHub 的使用
5. 英语写作能力
6. 计划性和执行力。

## 10.02
基本的框架已经构思完成，空闲的时候再进行抽象类的构造吧。  
Caffe 的应用框架在10月底之前完成吧。  

## 10.05
TensorFlow 的语法和资源显然更多更好，应老师的要求，准备用tensorflow处理。  
打算应用该模型转变最后的全连接层，达到想要的几个特定的手势分类，并在迁移学习的基础上，对新数据集进行训练。  

先搞定好caffe！利用fine tune感觉还是能做出效果的！最重要的是已经分离出来的。  

## 10.08
我意识到caffe与tensorflow的共同点在于一个东西，这个东西就是**核心的数学上的处理方法**，毕竟原理都是在构建和实现(神经)网络，这些都是数学上的事情。不同的只是框架上些许差异，数据结构不同，偏向不一样，计算方式不同，这是程序设计上的。
而且在我看来caffe对C++十分友好，tensorflow对python十分友好。tf上手快，学习资源系统化。caffe则很多平台不兼容问题，安装也是个问题，但它却有很多现成的caffe model和训练好的caffemodel文件，我想是出生比较早并且训练性能更加并且对图像处理提供很多工具的原因吧。
最后选择了在手势识别上就一直走caffe的应用层，工作主要是
1. 各个环境收集数据 (camera)
2. 处理得到可用数据集 (openCV process)
3. 利用数据集训练和测试caffemodel（finetune）
4. 应用模型和参数进行手势分类 (clssify)  

3天时间，有1.5天在弄1、2步骤，也写成一个不错的openCV处理mp4视频得到训练集并且自动命名和加入到txt文件而且还能统计数目，(对C++和caffe更加热爱了)。
然后有1天在设置solver和net文件，为了fine-tune而进行修改，看了不少东西，
觉得找这些知识比较好的途径是`GitHub上的issue`(虽然没有找到问题，并且发了issue最后也还是我自己close and comment)，但是就是感觉专业啊！还有`Google`到的知识，非常详细且正确性很强(不会有人像我半桶水就想着发些教程了)，还有就是`官方社区`的资源了(论专业谁能比得上)，我找到了社区翻译版的caffe教程，十分感动，里面描述了很多关键的东西，当然，看得懂源代码天下无敌。

**fine-tune train 遇到了一些`知识`，记录一下**  
* fine-tune实质上是**改变对应的输出数目**以适用自己的应用场景，又想利用到原模型的网络和权值，方法就是利用再训练。
  * 改变数目的那个层必须**修改名字**，是在官方文档看到的，caffemodel权值的加载是根据层的名字的。事实上也证明如此，如果不这么做，在加载权值的时候会hang with `Segment fault`，当修改好了名字之后，会有 *ignore layer （whose name has been changed）*，说明这就是fine-tune的核心之处。
  * fine-tune新增加的层**学习速率**要比原来快10倍以尽快收敛。
  * fine-tune有几种方式（貌似可以指定参数？），常用的一种只修改最后的全连接层（全连接层在GoogLeNet就是为了fine-tune）权值，一种是全部重新修改，我用到的是只修改最后fc层，用到的方法是禁止反向传递计算，`propagate_down: index`，index对应输入口bottom。在初始化网络的时候会提示哪些层不需要计算，所以说是可用的。
* fine-tune train是一种方式，加载权值后再进行训练，相当于先进行可靠的权值初始化，所以大大减少时间。
  * solver修改：主要是样本量很小的时候如何适应。
  * net 中data层的修改：输入层也让人头疼，因为ImageData是支持txt，然后自己转换的，但是却 *hang without any error prompt*，应该是windows上不兼容这个层，最后使用Data layer替换之，问题解决！（所谓问题的发现是根据运行进展来判断的，如果修改得当，那么进展会发生变化，是没有提示下的好办法，而如何修改可以根据网络文件的对比，层的深刻理解来进行。）
  * train log，用到了重定向 2>> ，但是用| tee的时候还是不能使用| 的错误。
  * 然而这么重要的工具caffe早就提供了，并且可以画出loss跟iter关系图！ [解析](https://www.cnblogs.com/Allen-rg/p/5822332.html) [更多画图](https://blog.csdn.net/u011070171/article/details/52936205)
    * Glog:实现对log文件的管理，指定log路径
    ```Bash
    GLOG_logtostderr=0 GLOG_log_dir=/home/liuyun/caffe/models/AAA/A12/Log/ \
    caffe.exe train ...
    ```
    * 解析log文件：parse_log.sh 生成train和test日志文件
    ```Bash
    ./parse_log.sh caffe.liuyun-860-088cn.root.log.INFO.20160830-090533.5367
    ```
    * 生成图片：plt_traing_log.py 注意名字
    ```Bash
    ./plot_training_log.py.example 6  train_loss.png caffe.liuyun-860-088cn.root.log
    ```
所以说，今天终于看到跑着的caffe了，并且能看到每400个迭代后loss值越来越小，非常感动。  
不过每400迭代大概需要10分钟，20000次就是500分钟=8小时15分钟，还是今晚睡觉的时候跑吧。  
接下来就是写成应用框架了，利用之前的设计模式知识！
